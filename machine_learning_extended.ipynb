{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "professional-square",
   "metadata": {},
   "source": [
    "## Plan\n",
    "1. Charger les données\n",
    "2. Split dataset\n",
    "3. Pretraitement des données\n",
    "       3.1. One hot encoding pour les données catégorielle\n",
    "       3.2. Normalisation de données numériques (pour le Regression Logistique)\n",
    "4. Random Forest\n",
    "       4.1. Faire apprendre le modèle (par défault, RandomizedSearch, GridSearchCV, cross-validation, best_clf)\n",
    "       4.2. Améliorer le modèle (parametrage, jouer avec le volume de données)\n",
    "       4.3. Faire apprendre le modèle après le paramètrage de l'étape précédente\n",
    "5. Feature importance\n",
    "6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-peoples",
   "metadata": {},
   "source": [
    "### 1. Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "desperate-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifteen-genius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>slope</th>\n",
       "      <th>cd_water</th>\n",
       "      <th>aspect</th>\n",
       "      <th>hill90</th>\n",
       "      <th>hill5</th>\n",
       "      <th>hill45</th>\n",
       "      <th>clc00</th>\n",
       "      <th>numpoints</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.98010</td>\n",
       "      <td>0.256047</td>\n",
       "      <td>9</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.36810</td>\n",
       "      <td>0.296268</td>\n",
       "      <td>2</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.86523</td>\n",
       "      <td>0.374666</td>\n",
       "      <td>2</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.56061</td>\n",
       "      <td>0.471633</td>\n",
       "      <td>2</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.50320</td>\n",
       "      <td>0.589352</td>\n",
       "      <td>10</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    slope  cd_water  aspect  hill90  hill5  hill45  clc00  numpoints  \\\n",
       "0   1  4.98010  0.256047       9     254      0     195    312          0   \n",
       "1   2  3.36810  0.296268       2     254      0     187    312          0   \n",
       "2   3  3.86523  0.374666       2     254      0     186    312          0   \n",
       "3   4  5.56061  0.471633       2     253      0     191    312          0   \n",
       "4   5  9.50320  0.589352      10     251      0     204    312          0   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/features_target.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "processed-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"aspect\", \"clc00\"]\n",
    "num_cols = [\"slope\", \"cd_water\", \"hill5\", \"hill45\", \"hill90\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-dispute",
   "metadata": {},
   "source": [
    "### 2. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acute-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"id\", \"numpoints\", \"target\"], axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recognized-philip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24678, 7), (10577, 7))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-consortium",
   "metadata": {},
   "source": [
    "In order to not make the data leaks, we going to make all the data ingeneering after spliting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-scratch",
   "metadata": {},
   "source": [
    "### 3. Pretraitement des données\n",
    "#### 3.1. One hot encoding pour les données catégorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "municipal-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24678, 47)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode categorical features in train set\n",
    "X_train = pd.concat([X_train[num_cols],\n",
    "                    pd.get_dummies(X_train.aspect),\n",
    "                    pd.get_dummies(X_train.clc00)], axis=1)\n",
    "\n",
    "# check if all is ok after data spliting\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "straight-northeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10577, 47)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode categorical features in test set\n",
    "X_test = pd.concat([X_test[num_cols],\n",
    "                    pd.get_dummies(X_test.aspect),\n",
    "                    pd.get_dummies(X_test.clc00)], axis=1)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coral-trial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество признаков в train: 47\n",
      "Количество признаков в valid: 47\n",
      "{411}\n",
      "{421}\n"
     ]
    }
   ],
   "source": [
    "# ici nous allons nous assurer que les deux jeux de données ont la même nombre de champs\n",
    "print('Nombre de champs dans le train set:', len(X_train.columns))\n",
    "print('Nombre de champs dans le test set: ', len(X_test.columns))\n",
    "\n",
    "print(set(X_train.columns) - set(X_test.columns))\n",
    "print(set(X_test.columns) - set(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "removed-stockholm",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>cd_water</th>\n",
       "      <th>hill5</th>\n",
       "      <th>hill45</th>\n",
       "      <th>hill90</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>322</th>\n",
       "      <th>323</th>\n",
       "      <th>324</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>512</th>\n",
       "      <th>521</th>\n",
       "      <th>523</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11431</th>\n",
       "      <td>12.208700</td>\n",
       "      <td>0.337930</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26454</th>\n",
       "      <td>3.785660</td>\n",
       "      <td>0.084686</td>\n",
       "      <td>29</td>\n",
       "      <td>185</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32394</th>\n",
       "      <td>6.963620</td>\n",
       "      <td>0.137171</td>\n",
       "      <td>28</td>\n",
       "      <td>183</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14239</th>\n",
       "      <td>1.504800</td>\n",
       "      <td>0.158528</td>\n",
       "      <td>22</td>\n",
       "      <td>180</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>1.576570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28818</th>\n",
       "      <td>1.459390</td>\n",
       "      <td>0.132887</td>\n",
       "      <td>27</td>\n",
       "      <td>183</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17265</th>\n",
       "      <td>1.564830</td>\n",
       "      <td>0.073344</td>\n",
       "      <td>18</td>\n",
       "      <td>177</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31724</th>\n",
       "      <td>7.530700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820</th>\n",
       "      <td>6.790660</td>\n",
       "      <td>0.113246</td>\n",
       "      <td>43</td>\n",
       "      <td>194</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26828</th>\n",
       "      <td>0.481125</td>\n",
       "      <td>0.089470</td>\n",
       "      <td>20</td>\n",
       "      <td>179</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10577 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           slope  cd_water  hill5  hill45  hill90  1  2  3  4  5  ...  322  \\\n",
       "11431  12.208700  0.337930      0     145     249  0  0  0  1  0  ...    0   \n",
       "26454   3.785660  0.084686     29     185     254  0  1  0  0  0  ...    0   \n",
       "32394   6.963620  0.137171     28     183     253  0  0  1  0  0  ...    0   \n",
       "14239   1.504800  0.158528     22     180     254  0  0  0  0  0  ...    0   \n",
       "4145    1.576570  0.000000      0     175     254  0  0  0  0  0  ...    0   \n",
       "...          ...       ...    ...     ...     ... .. .. .. .. ..  ...  ...   \n",
       "28818   1.459390  0.132887     27     183     254  0  0  0  0  0  ...    0   \n",
       "17265   1.564830  0.073344     18     177     254  0  0  0  0  0  ...    0   \n",
       "31724   7.530700  0.000000      0     175     252  0  0  0  0  0  ...    0   \n",
       "12820   6.790660  0.113246     43     194     253  0  0  0  0  0  ...    0   \n",
       "26828   0.481125  0.089470     20     179     254  0  0  0  0  0  ...    0   \n",
       "\n",
       "       323  324  331  332  333  334  512  521  523  \n",
       "11431    0    0    0    0    0    0    0    0    0  \n",
       "26454    0    0    0    0    0    0    0    0    0  \n",
       "32394    0    0    0    0    0    0    0    0    0  \n",
       "14239    0    0    0    0    0    0    0    0    0  \n",
       "4145     0    0    0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "28818    1    0    0    0    0    0    0    0    0  \n",
       "17265    0    0    0    0    0    0    0    0    0  \n",
       "31724    1    0    0    0    0    0    0    0    0  \n",
       "12820    0    1    0    0    0    0    0    0    0  \n",
       "26828    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[10577 rows x 46 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't do that\n",
    "X_train.drop([411], axis=1)\n",
    "X_test.drop([421], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-portal",
   "metadata": {},
   "source": [
    "Maintenant nous avons 2 jeux de données\n",
    "- train (19830 objects (rows))\n",
    "- valid (6611 objects)\n",
    "- test (8814 objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-natural",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-advocate",
   "metadata": {},
   "source": [
    "### Faire apprendre le modèle\n",
    "- avec les paramètres par défault, \n",
    "- RandomizedSearch, \n",
    "- GridSearchCV, \n",
    "- cross-validation, \n",
    "- best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "genuine-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-community",
   "metadata": {},
   "source": [
    "Créer un object qui est un classificateur avec les parmètres par défault.\n",
    "\n",
    "Nous allons fixer le paramètre random_state pour pouvoir réproduire les données par la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "southern-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "clf_rf1 = clf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-raising",
   "metadata": {},
   "source": [
    "La metrique qualité sera le ROC-AUC parce que notre class visé est unbalancé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "suburban-printer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC для обучающей выборки:     0.9819728002890791\n",
      "ROC-AUC для валидационной выборки: 0.6195884060868989\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "print('ROC-AUC train set:', roc_auc_score(y_train, clf_rf1.predict_proba(X_train)[:,1]))\n",
    "print('ROC-AUC test set: ',  roc_auc_score(y_test, clf_rf1.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-cream",
   "metadata": {},
   "source": [
    "Метрика ROC-AUC показала высокое качество на обучающей выборке, но всего 62 качества на тестовой. На лицо явное переобучение модели. Постараемся улучшить её обучающую способность. Для начала воспользуемся RandomizedSearch, чтобы уменьшить диапазон рассматриваемых наилучших значений параметров модели. Затем воспользуемся GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-cleaning",
   "metadata": {},
   "source": [
    "#### RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-missile",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "educated-respondent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV based on data obtained in RandomizedSearchCV\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "params_rf = {'max_depth': [20, 26],\n",
    "             'min_samples_split': [6, 7],\n",
    "             'min_samples_leaf': [3, 5],\n",
    "             'n_estimators':[200, 350, 600]}\n",
    "\n",
    "search_rf_grid = GridSearchCV(clf_rf, params_rf, \n",
    "                                cv=5, n_jobs=-1)\n",
    "\n",
    "search_rf_grid.fit(X_train, y_train)\n",
    "search_rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "mineral-fairy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC для обучающей выборки:     0.9751290664807163\n",
      "ROC-AUC для валидационной выборки: 0.616873292287433\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "print('ROC-AUC train set:    ', roc_auc_score(y_train, search_rf_grid.predict_proba(X_train)[:,1]))\n",
    "print('ROC-AUC test set :', roc_auc_score(y_test, search_rf_grid.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-judgment",
   "metadata": {},
   "source": [
    "Итак наилучшие параметры, полученные благодаря GridSearchCV sont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "czech-corpus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=5, min_samples_split=4,\n",
       "                       n_estimators=800, random_state=42)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = RandomForestClassifier(n_estimators=800,\n",
    "                                 criterion='entropy',\n",
    "                                 max_depth=5,\n",
    "                                 min_samples_split=4,  \n",
    "                                 min_samples_leaf=1, \n",
    "                                 random_state=42)\n",
    "\n",
    "best_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "younger-discretion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC для обучающей выборки:     0.7166262637876225\n",
      "ROC-AUC для тестовой выборки:      0.6263397676407525\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "y_pred = best_rf.predict_proba(X_test)[:,1]\n",
    "# y_true is y_test\n",
    "\n",
    "# score\n",
    "print('ROC-AUC для обучающей выборки:    ', roc_auc_score(y_train, best_rf.predict_proba(X_train)[:,1]))\n",
    "# print('ROC-AUC для валидационной выборки:',  roc_auc_score(y_valid, y_pred))\n",
    "print('ROC-AUC для тестовой выборки:     ',  roc_auc_score(y_test, best_rf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-chart",
   "metadata": {},
   "source": [
    "### 4.2. Améliorer le modèle (parametrage, jouer avec le volume de données)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-shift",
   "metadata": {},
   "source": [
    "Обучающая способность модели все еще неудовлетворительная. Чтобы понять, как улучшить модель, обратимся к литературе и веб источникам.\n",
    "\n",
    "https://towardsdatascience.com/improving-random-forest-in-python-part-1-893916666cd\n",
    "\n",
    "Есть три общих подхода к улучшению существующей модели машинного обучения:\n",
    "\n",
    "- Используйте больше (высококачественных) данных и функций\n",
    "- Настроить гиперпараметры алгоритма\n",
    "- Попробуйте другие алгоритмы\n",
    "\n",
    "Они представлены в том порядке, в котором я их обычно пробую.\n",
    "\n",
    "- отбор фичей, уменьшение их количества\n",
    "- Другие способы уменьшения количества признаков: PCA, ICA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-briefs",
   "metadata": {},
   "source": [
    "#### 4.2.1. Попробуем вручную подобрать параметры обучения модели.\n",
    "Для начала посмотрим, что дает варьирование числа фолдов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = []\n",
    "for n in range(3, 7):\n",
    "    model_rf = RandomForestClassifier(random_state=42)\n",
    "    params_grid = {'max_depth':[5], \"n_estimators\":[350], 'criterion':['entropy']}\n",
    "    search_grid = GridSearchCV(model_rf, params_grid, n_jobs=-1, cv=n)\n",
    "    search_grid.fit(X_train, y_train)\n",
    "    y_pred = search_grid.predict_proba(X_train)[:,1]\n",
    "    auc = roc_auc_score(y_train, y_pred)\n",
    "    print(\"cv =\", n, \":\", auc)\n",
    "    e.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-intelligence",
   "metadata": {},
   "source": [
    "Итак, видим, что...\n",
    "\n",
    "Возможно дело в недостатке данных? Проверим и это предположение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-compromise",
   "metadata": {},
   "source": [
    "#### 4.2.2. Зависимость качества обучения от объема обучающей выборки\n",
    "Проанализируем, как зависит качество модели от количества обучающих объектов выборки. \n",
    "\n",
    "источник: coursera - Spetialisation Data Science - Machine Learning\n",
    "\n",
    "Для этого создадим модель. Для начала будем строить случайный лес над 50 деревьями, каждый из которых будет иметь глубину не больше 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unexpected-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn import ensemble, metrics\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = ensemble.RandomForestClassifier(n_estimators = 50, max_depth = 2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-reservoir",
   "metadata": {},
   "source": [
    "И теперь давайте построим следующий график — нам будет интересно посмотреть, как меняется качество на обучающей и тестовой выборке, в зависимости от того, на скольких объектах мы обучаемся.\n",
    "\n",
    "Для того чтобы получить такие графики, у sklearn есть специальная функция под названием learning_curve. Она позволяет нам сделать следующее — ей можно передать на вход нужный нам алгоритм, передать данные и целевую функцию, а также сказать, в каких пропорциях мы хотим обучаться, то есть на каких долях обучающей выборки мы хотим строить модель.\n",
    "\n",
    "После этого с помощью этого метода будут построены несколько моделей, мы получим оценку качества на каждом объеме обучающей выборки, и нам будут возвращены размер обучающей выборки, оценки качества на «трейне» и оценка качества на тесте.\n",
    "\n",
    "Имея такие данные, мы легко сможем проанализировать, как качество на обучении и тесте меняется от объема обучающей выборки. Вот давайте сделаем такую вещь.\n",
    "\n",
    "Мы передаем в функцию наш классификатор, который мы создали ранее. Далее передаем туда данные, которые мы также подготовили на предварительном шаге. И говорим, что мы будем обучать модель на следующих данных: сначала мы возьмем 0,1 от обучающей выборки и далее будем двигаться с шагом 0,2 до 1. Оценивать качество будем с помощью уже знакомой нам метрики roc-auc и будем делать кросс-валидацию на 3 фолда. Давайте запустим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=5, 100% of data\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf_rf, X_train, y_train, \n",
    "                                                        train_sizes=np.arange(0.1,1, 0.2), \n",
    "                                                        cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_sizes)\n",
    "print(train_scores.mean(axis = 1))\n",
    "print(test_scores.mean(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-psychology",
   "metadata": {},
   "source": [
    "Для начала мы видим, что train_sizes — размер обучающей выборки — был преобразован из долей в конкретное количество объектов, на которых мы обучались. То есть мы видим, что минимальное количество обучающих объектов в рамках нашего эксперимента составляет 250, максимальное — 2250. Также нам доступны оценки качества на обучении и оценки качества на тесте. Так как у нас проводилась кросс-валидация, я сразу же сделала усреднение по всем фолдам — это делается с помощью команды mean. Аргумент axis = 1 означает, что мы будем усреднять по строчкам. Вот в данном случае каждая строка — это результат измерения кросс-валидации, поэтому нам это подходит.\n",
    "\n",
    "Теперь давайте построим график. Сразу добавим на график сетку и будем строить две кривые — качество обучения на обучающей выборке и на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.grid(True)\n",
    "pylab.plot(train_sizes, train_scores.mean(axis = 1), 'g-', marker='o', label='train')\n",
    "pylab.plot(train_sizes, test_scores.mean(axis = 1), 'r-', marker='o', label='test')\n",
    "pylab.ylim((0.0, 1.05))\n",
    "pylab.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-excellence",
   "metadata": {},
   "source": [
    "мы видим, что в начале качество на обучающей выборке падает — приблизительно до отметки 1250 деревьев, и дальше качество меняется очень медленно. С другой стороны, на тестовой выборке качество продолжает расти приблизительно до этой же точки, и дальше оно также перестает меняться. Какой вывод мы можем сделать из этого? Дальнейший рост обучающей выборки вряд ли скажется на качестве нашей модели. Это говорит о том, что модель данной сложности не может многое выиграть за счет того, что мы обогатим данные. Что же делать в такой ситуации? Кривые обучения для деревьев большей глубины\n",
    "\n",
    "Давайте попробуем увеличить сложность модели — возможно, это приведет к улучшению ее качества. Так как мы с вами обучали модель на деревьях глубины 2, давайте увеличим глубину деревьев — это даст нам дополнительные возможности.\n",
    "\n",
    "Снова создаем классификатор RandomForestClassifier, но в этот раз указываем ему параметр max_depth = 10 — это максимально возможная глубина деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=18\n",
    "clf_rf = ensemble.RandomForestClassifier(n_estimators = 600, max_depth = 2, random_state = 1)\n",
    "\n",
    "\n",
    "# Теперь давайте еще раз запустим команду learning_curve и \n",
    "# построим кривую обучения на тесте и на обучении, при этом \n",
    "# мы будем делать это по тем же самым точкам, по тем же \n",
    "# самым долям обучающей выборки.\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf_rf, X_train, y_train, \n",
    "                                                        train_sizes=np.arange(0.1,1, 0.2), \n",
    "                                                        cv=5, scoring='roc_auc')\n",
    "print(train_sizes)\n",
    "print(train_scores.mean(axis = 1))\n",
    "print(test_scores.mean(axis = 1))\n",
    "\n",
    "pylab.grid(True)\n",
    "pylab.plot(train_sizes, train_scores.mean(axis = 1), 'g-', marker='o', label='train')\n",
    "pylab.plot(train_sizes, test_scores.mean(axis = 1), 'r-', marker='o', label='test')\n",
    "pylab.ylim((0.0, 1.05))\n",
    "pylab.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-wyoming",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "При 50 деревьях не хватает обобщающей способности модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-picnic",
   "metadata": {},
   "source": [
    "#### 4.2.3. Imputing the value to target class\n",
    "\n",
    "(résoudre le problème de classes unbalancées)\n",
    "\n",
    "Попробуем решить проблему несбалансированности выборки.\n",
    "\n",
    "    a - imputing\n",
    "    b - changer le datase, obtenit plus de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-samuel",
   "metadata": {},
   "source": [
    "### 4.2.4. Feature Importance\n",
    "\n",
    "Отбор признаков является важным этапом построения алгоритмов машинногообучения. Данный этап необходим, чтобы избавиться от шумовых признаков и бла-годаря этому улучшить качество и ускорить работу алгоритмов. Проведенные экспе-рименты подтверждают, что алгоритмы отбора признаков с помощью Random Forestэффективно справляется со своей задачей\n",
    "http://www.machinelearning.ru/wiki/images/9/96/RysmyatovaCourseFile.pdf\n",
    "\n",
    "In order to quantify the usefulness of all the variables in the entire random forest, we can look at the relative importances of the variables. The importances returned in Skicit-learn represent how much including a particular variable improves the prediction. The actual calculation of the importance is beyond the scope of this post, but we can use the numbers to make relative comparisons between variables.\n",
    "\n",
    "Крооме того, опеределение и классификация важности признаков привность некоторые интересные элементы в вопрос факторах, характеризующих места, наиболее пригодные для заселения древними. Характеристики территорий, на которых было найдено больше всего следов пребывания, стоянок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для отрисовки важности фичей 1\n",
    "\n",
    "imp = pd.DataFrame(best_rf.feature_importances_, index=X_train.columns, columns=['importance'])\n",
    "imp.sort_values('importance').plot(kind='barh', figsize=(12, 8));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
